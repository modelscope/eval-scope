{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!rm -rf llmuses-0.0.3-py3-none-any.whl\n",
    "!rm -rf requirements.txt\n",
    "!rm -rf question_mini.jsonl\n",
    "!rm -rf review_gpt4.jsonl\n",
    "!rm -rf cfg_arena.yaml\n",
    "!rm -rf lmsys.jsonl\n",
    "\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/llmuses-0.0.3-py3-none-any.whl\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/requirements.txt\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/question_mini.jsonl\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/review_gpt4.jsonl\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/cfg_arena.yaml\n",
    "!wget https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/lmsys.jsonl\n",
    "\n",
    "!ls -l"
   ],
   "metadata": {
    "id": "kXZa5j9xIAR6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "514e5259-fe9f-409e-b14a-94f387198f9e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2023-07-20 15:25:15--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/llmuses-0.0.3-py3-none-any.whl\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 59807 (58K) [application/octet-stream]\n",
      "Saving to: ‘llmuses-0.0.3-py3-none-any.whl’\n",
      "\n",
      "llmuses-0.0.3-py3-n 100%[===================>]  58.41K   123KB/s    in 0.5s    \n",
      "\n",
      "2023-07-20 15:25:17 (123 KB/s) - ‘llmuses-0.0.3-py3-none-any.whl’ saved [59807/59807]\n",
      "\n",
      "--2023-07-20 15:25:17--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/requirements.txt\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 204 [text/plain]\n",
      "Saving to: ‘requirements.txt’\n",
      "\n",
      "requirements.txt    100%[===================>]     204  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-20 15:25:18 (132 MB/s) - ‘requirements.txt’ saved [204/204]\n",
      "\n",
      "--2023-07-20 15:25:18--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/question_mini.jsonl\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 556 [application/octet-stream]\n",
      "Saving to: ‘question_mini.jsonl’\n",
      "\n",
      "question_mini.jsonl 100%[===================>]     556  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-20 15:25:19 (391 MB/s) - ‘question_mini.jsonl’ saved [556/556]\n",
      "\n",
      "--2023-07-20 15:25:19--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/review_gpt4.jsonl\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28944 (28K) [application/octet-stream]\n",
      "Saving to: ‘review_gpt4.jsonl’\n",
      "\n",
      "review_gpt4.jsonl   100%[===================>]  28.27K   118KB/s    in 0.2s    \n",
      "\n",
      "2023-07-20 15:25:20 (118 KB/s) - ‘review_gpt4.jsonl’ saved [28944/28944]\n",
      "\n",
      "--2023-07-20 15:25:20--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/cfg_arena.yaml\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1814 (1.8K) [text/yaml]\n",
      "Saving to: ‘cfg_arena.yaml’\n",
      "\n",
      "cfg_arena.yaml      100%[===================>]   1.77K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-20 15:25:21 (27.9 MB/s) - ‘cfg_arena.yaml’ saved [1814/1814]\n",
      "\n",
      "--2023-07-20 15:25:21--  https://sail-moe.oss-cn-hangzhou.aliyuncs.com/banyang/llm-eval/lmsys.jsonl\n",
      "Resolving sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)... 118.31.219.192\n",
      "Connecting to sail-moe.oss-cn-hangzhou.aliyuncs.com (sail-moe.oss-cn-hangzhou.aliyuncs.com)|118.31.219.192|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975 (3.9K) [application/octet-stream]\n",
      "Saving to: ‘lmsys.jsonl’\n",
      "\n",
      "lmsys.jsonl         100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-20 15:25:22 (62.9 MB/s) - ‘lmsys.jsonl’ saved [3975/3975]\n",
      "\n",
      "total 112\n",
      "-rw-r--r-- 1 root root  1814 Jul 18 03:49 cfg_arena.yaml\n",
      "-rw-r--r-- 1 root root 59807 Jul 20 10:44 llmuses-0.0.3-py3-none-any.whl\n",
      "-rw-r--r-- 1 root root  3975 Jul 18 03:51 lmsys.jsonl\n",
      "-rw-r--r-- 1 root root   556 Jul 20 10:27 question_mini.jsonl\n",
      "-rw-r--r-- 1 root root   204 Jul 20 10:27 requirements.txt\n",
      "-rw-r--r-- 1 root root 28944 Jul 18 02:47 review_gpt4.jsonl\n",
      "drwxr-xr-x 1 root root  4096 Jul 18 13:43 sample_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzMJ-bmeXPmX",
    "outputId": "f906e688-4619-4fa5-d364-0175bc035b0e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jul 20 15:25:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Note: 需要重启kernel\n",
    "\n",
    "!pip uninstall llmuses -y\n",
    "!pip install llmuses-0.0.3-py3-none-any.whl\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwA36CtZIJUo",
    "outputId": "2c9db278-9132-4571-e813-5c535d20b71e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[33mWARNING: Skipping llmuses as it is not installed.\u001B[0m\u001B[33m\n",
      "\u001B[0mProcessing ./llmuses-0.0.3-py3-none-any.whl\n",
      "Installing collected packages: llmuses\n",
      "Successfully installed llmuses-0.0.3\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Collecting dashscope (from -r requirements.txt (line 2))\n",
      "  Downloading dashscope-1.3.1-py3-none-any.whl (56 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.2/56.2 kB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.6.2)\n",
      "Collecting jsonlines (from -r requirements.txt (line 4))\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.8.1)\n",
      "Collecting openai (from -r requirements.txt (line 6))\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m73.6/73.6 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (5.13.1)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (6.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
      "Collecting requests-toolbelt (from -r requirements.txt (line 13))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.5/54.5 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting rouge-score (from -r requirements.txt (line 14))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting sacrebleu (from -r requirements.txt (line 15))\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m118.9/118.9 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.12.2)\n",
      "Collecting simple-ddl-parser (from -r requirements.txt (line 18))\n",
      "  Downloading simple_ddl_parser-0.30.0-py3-none-any.whl (59 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.8/59.8 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting streamlit (from -r requirements.txt (line 19))\n",
      "  Downloading streamlit-1.24.1-py2.py3-none-any.whl (8.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.9/8.9 MB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (4.65.0)\n",
      "Collecting transformers (from -r requirements.txt (line 21))\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.4/7.4 MB\u001B[0m \u001B[31m73.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from dashscope->-r requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 5)) (8.1.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 7)) (1.22.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->-r requirements.txt (line 8)) (8.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score->-r requirements.txt (line 14)) (1.16.0)\n",
      "Collecting portalocker (from sacrebleu->-r requirements.txt (line 15))\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r requirements.txt (line 15)) (0.8.10)\n",
      "Collecting colorama (from sacrebleu->-r requirements.txt (line 15))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r requirements.txt (line 15)) (4.9.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 16)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 16)) (3.1.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 17)) (3.7.1)\n",
      "Collecting ply<4.0,>=3.11 (from simple-ddl-parser->-r requirements.txt (line 18))\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.6/49.6 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r requirements.txt (line 19)) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (5.3.1)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/lib/python3/dist-packages (from streamlit->-r requirements.txt (line 19)) (4.6.4)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (23.1)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (8.4.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (3.20.3)\n",
      "Collecting pympler<2,>=0.9 (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m164.8/164.8 kB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (13.4.2)\n",
      "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (4.7.1)\n",
      "Collecting tzlocal<5,>=1.1 (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting gitpython!=3.1.19,<4,>=3 (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m188.5/188.5 kB\u001B[0m \u001B[31m23.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pydeck<1,>=0.1.dev5 (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.8/4.8 MB\u001B[0m \u001B[31m105.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r requirements.txt (line 19)) (6.3.1)\n",
      "Collecting watchdog (from streamlit->-r requirements.txt (line 19))\n",
      "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m82.1/82.1 kB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 21)) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->-r requirements.txt (line 21))\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m268.8/268.8 kB\u001B[0m \u001B[31m31.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 21))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m112.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 21))\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m81.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (4.3.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (0.12.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 19))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.7/62.7 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r requirements.txt (line 21)) (2023.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 17)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 17)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 17)) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 17)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 17)) (3.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->-r requirements.txt (line 19)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.11.0->streamlit->-r requirements.txt (line 19)) (2.14.0)\n",
      "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 19))\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators<1,>=0.2->streamlit->-r requirements.txt (line 19)) (4.4.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 2)) (1.3.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit->-r requirements.txt (line 19))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (2.1.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 19)) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit->-r requirements.txt (line 19)) (0.1.2)\n",
      "Collecting tzdata (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit->-r requirements.txt (line 19))\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m341.8/341.8 kB\u001B[0m \u001B[31m38.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: rouge-score, validators\n",
      "  Building wheel for rouge-score (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=145fffece7373344e8853aa5abdb9a4d0bb8e3d5d123976b01f416874d650813\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for validators (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=43289145c70828404271d7c9b158c8b069eeb518326f0de75cab6048b2278b8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
      "Successfully built rouge-score validators\n",
      "Installing collected packages: tokenizers, safetensors, ply, watchdog, validators, tzdata, smmap, simple-ddl-parser, pympler, portalocker, jsonlines, colorama, sacrebleu, rouge-score, requests-toolbelt, pytz-deprecation-shim, pydeck, huggingface-hub, gitdb, tzlocal, transformers, openai, gitpython, dashscope, streamlit\n",
      "  Attempting uninstall: tzlocal\n",
      "    Found existing installation: tzlocal 5.0.1\n",
      "    Uninstalling tzlocal-5.0.1:\n",
      "      Successfully uninstalled tzlocal-5.0.1\n",
      "Successfully installed colorama-0.4.6 dashscope-1.3.1 gitdb-4.0.10 gitpython-3.1.32 huggingface-hub-0.16.4 jsonlines-3.1.0 openai-0.27.8 ply-3.11 portalocker-2.7.0 pydeck-0.8.1b0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 requests-toolbelt-1.0.0 rouge-score-0.1.2 sacrebleu-2.3.1 safetensors-0.3.1 simple-ddl-parser-0.30.0 smmap-5.0.0 streamlit-1.24.1 tokenizers-0.13.3 transformers-4.31.0 tzdata-2023.3 tzlocal-4.3.1 validators-0.20.0 watchdog-3.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import llmuses\n",
    "\n",
    "print('>version: ', llmuses.__version__)\n",
    "print('>datetime: ', llmuses.__release_datetime__)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqKZrLARIPYA",
    "outputId": "f21a068a-4bf3-49c7-a874-bb18907cf8a5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">version:  0.0.3\n",
      ">datetime:  2023-07-18 16:30:00\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run arena evaluation\n",
    " - ELO Rating"
   ],
   "metadata": {
    "id": "ye0vnVre35r5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "from llmuses.constants import EvalTaskConfig, ArenaMode\n",
    "from llmuses.evaluator.rating_eval import RatingEvaluate\n",
    "from llmuses.utils.logger import get_logger\n",
    "from llmuses.utils.utils import get_obj_from_cfg, yaml_to_dict\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "\n",
    "class ArenaWorkflow:\n",
    "\n",
    "    def __init__(self, cfg_file: str, **kwargs):\n",
    "\n",
    "        self.cfg_dict = yaml_to_dict(cfg_file)\n",
    "        # logger.info(f'Config: {self.cfg_dict}')\n",
    "\n",
    "        self.question_file: str = self.cfg_dict.get('question_file')\n",
    "\n",
    "        self.answers_gen: dict = self.cfg_dict.get('answers_gen', {})\n",
    "        for k in self.answers_gen.keys():\n",
    "            self.answers_gen[k] = ArenaWorkflow._get_obj_from_cfg(\n",
    "                self.answers_gen[k])\n",
    "\n",
    "        self.reviews_gen: dict = self.cfg_dict.get('reviews_gen', {})\n",
    "        self.reviewer_cfg: dict = ArenaWorkflow._get_obj_from_cfg(\n",
    "            self.reviews_gen.get('reviewer', {}))\n",
    "        self.prompt_file = os.path.abspath(self.reviews_gen.get('prompt_file'))\n",
    "        self.review_file = os.path.abspath(self.reviews_gen.get('review_file'))\n",
    "\n",
    "        self.rating_gen: dict = self.cfg_dict.get('rating_gen', {})\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_obj_from_cfg(obj_cfg: dict):\n",
    "        cls_ref = obj_cfg.get(EvalTaskConfig.CLASS_REF, None)\n",
    "        if not cls_ref:\n",
    "            logger.warning(\n",
    "                f'Class reference is not specified in config: {obj_cfg}')\n",
    "            return obj_cfg\n",
    "\n",
    "        cls = get_obj_from_cfg(cls_ref)\n",
    "        obj_cfg[EvalTaskConfig.CLASS_REF] = cls\n",
    "\n",
    "        return obj_cfg\n",
    "\n",
    "    def get_answers(self):\n",
    "\n",
    "        for model_id, cfg in self.answers_gen.items():\n",
    "            enable = cfg.get(EvalTaskConfig.ENABLE, True)\n",
    "            if not enable:\n",
    "                logger.info(\n",
    "                    f'Skip model {model_id} because it is not enabled.')\n",
    "                continue\n",
    "\n",
    "            model_cls = cfg.get(EvalTaskConfig.CLASS_REF)\n",
    "            if not model_cls:\n",
    "                logger.warning(\n",
    "                    f'Skip model {model_id} because class reference '\n",
    "                    f'is not specified.')\n",
    "                continue\n",
    "            model_args = cfg.get(EvalTaskConfig.CLASS_ARGS, {})\n",
    "\n",
    "            input_kwargs = dict()\n",
    "            input_kwargs['model'] = model_id\n",
    "            input_kwargs['question_file'] = self.question_file\n",
    "            input_kwargs['output_file'] = cfg.get('output_file')\n",
    "            input_kwargs.update(model_args)\n",
    "            logger.info(f'Calling the model: {model_id} ...')\n",
    "            model_obj = model_cls(**input_kwargs)\n",
    "\n",
    "            # model_obj.run_dummy()  # Note: only for test\n",
    "            model_obj.run()\n",
    "            logger.info(f'Answers generated by model {model_id} '\n",
    "                        f'are saved to {input_kwargs[\"output_file\"]}.')\n",
    "\n",
    "    def get_reviews(self):\n",
    "        enable = self.reviews_gen.get(EvalTaskConfig.ENABLE, True)\n",
    "        if enable:\n",
    "            reviewer_cls = self.reviewer_cfg.get(EvalTaskConfig.CLASS_REF)\n",
    "            if not reviewer_cls:\n",
    "                logger.warning('Skip reviews generation because '\n",
    "                               'class reference is not specified.')\n",
    "                return\n",
    "            reviewer_args = self.reviewer_cfg.get(EvalTaskConfig.CLASS_ARGS,\n",
    "                                                  {})\n",
    "            target_answers = self.reviews_gen.get('target_answers', [])\n",
    "            target_answers = [\n",
    "                os.path.abspath(file_path) for file_path in target_answers\n",
    "            ]\n",
    "\n",
    "            baseline_file = self.reviews_gen.get('baseline_file', None)\n",
    "            if baseline_file:\n",
    "                baseline_file = os.path.abspath(baseline_file)\n",
    "\n",
    "            reference_file = self.reviews_gen.get('reference_file', None)\n",
    "            if reference_file:\n",
    "                reference_file = os.path.abspath(reference_file)\n",
    "\n",
    "            cache_file = self.reviews_gen.get('cache_file', None)\n",
    "            if cache_file:\n",
    "                cache_file = os.path.abspath(cache_file)\n",
    "\n",
    "            input_kwargs = dict(\n",
    "                prompt_file=self.prompt_file,\n",
    "                answer_file_list=target_answers,\n",
    "                baseline_file=baseline_file,\n",
    "                reference_file=reference_file,\n",
    "                review_file=self.review_file,\n",
    "                reviewer_args=reviewer_args,\n",
    "                cache_file=cache_file)\n",
    "            reviewer_obj = reviewer_cls(**input_kwargs)\n",
    "\n",
    "            reviewer_obj.run()\n",
    "            logger.info(f'Reviews generated by reviewer '\n",
    "                        f'are saved to {self.review_file}.')\n",
    "\n",
    "        else:\n",
    "            logger.warning(\n",
    "                'Skip reviews generation because it is not enabled.')\n",
    "\n",
    "    def get_rating_results(self):\n",
    "        enable = self.rating_gen.get(EvalTaskConfig.ENABLE, True)\n",
    "        if enable:\n",
    "            report_file = os.path.abspath(self.rating_gen.get('report_file'))\n",
    "            metrics = self.rating_gen.get('metrics', ['elo'])\n",
    "            baseline_model = self.rating_gen.get(\n",
    "                'baseline_model') if metrics[0] == 'pairwise' else None\n",
    "            ae = RatingEvaluate(metrics=metrics, baseline_model=baseline_model)\n",
    "            res_list = ae.run(self.review_file)\n",
    "            rating_df = res_list[0]\n",
    "            logger.info(f'Rating results:\\n{rating_df}')\n",
    "            rating_df.to_csv(report_file, index=True)\n",
    "            logger.info(f'Rating results are saved to {report_file}.')\n",
    "        else:\n",
    "            logger.warning('Skip rating because it is not enabled.')\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # Get all answers\n",
    "        self.get_answers()\n",
    "\n",
    "        # Get all reviews\n",
    "        self.get_reviews()\n",
    "\n",
    "        # Get rating results\n",
    "        self.get_rating_results()\n",
    "\n",
    "        logger.info('*** Arena workflow is finished. ***')\n",
    "\n"
   ],
   "metadata": {
    "id": "uJCDU6moO5yr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%env OPENAI_API_KEY=xxx\n",
    "\n",
    "def main():\n",
    "\n",
    "    ques_file = 'question_mini.jsonl'\n",
    "    cfg_file = 'cfg_arena.yaml'\n",
    "\n",
    "    arena_workflow = ArenaWorkflow(cfg_file=cfg_file)\n",
    "    arena_workflow.run()\n",
    "\n",
    "\n",
    "main()"
   ],
   "metadata": {
    "id": "oGX8hFK_g95c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "783626cd-c775-43e8-9f5d-c5be9505ba18"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-07-20 10:45:13,683 - llmuses - WARNING - Class reference is not specified in config: {'enable': False, 'ref': None, 'args': {'max_tokens': 512, 'temperature': 0.2}, 'output_file': 'llmuses/registry/data/arena/answers/answer_vicuna-13b.jsonl'}\n",
      "2023-07-20 10:45:13,689 - llmuses - WARNING - Class reference is not specified in config: {'enable': False, 'ref': None, 'args': {'max_tokens': 512, 'temperature': 0.2}, 'output_file': 'llmuses/registry/data/arena/answers/answer_llama-7b.jsonl'}\n",
      "2023-07-20 10:45:13,692 - llmuses - INFO - Calling the model: gpt-3.5-turbo ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-07-20 10:46:17,469 - llmuses - INFO - Dump data to answer_gpt35.jsonl successfully.\n",
      "2023-07-20 10:46:17,470 - llmuses - INFO - Answers generated by model gpt-3.5-turbo are saved to answer_gpt35.jsonl.\n",
      "2023-07-20 10:46:17,472 - llmuses - INFO - Skip model vicuna-13b because it is not enabled.\n",
      "2023-07-20 10:46:17,473 - llmuses - INFO - Skip model llama-7b because it is not enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run battles for models ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-07-20 10:46:58,172 - llmuses - INFO - Dump data to /content/review_gpt4.jsonl successfully.\n",
      "2023-07-20 10:46:58,174 - llmuses - INFO - Reviews generated by reviewer are saved to /content/review_gpt4.jsonl.\n",
      "2023-07-20 10:46:58,186 - llmuses - INFO - Rating results:\n",
      "                Model  Elo_Rating\n",
      "0  gpt-3.5-turbo-0613      1000.0\n",
      "2023-07-20 10:46:58,190 - llmuses - INFO - Rating results are saved to /content/elo_rating.csv.\n",
      "2023-07-20 10:46:58,191 - llmuses - INFO - *** Arena workflow is finished. ***\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "5bWZqLXf2VKG"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
